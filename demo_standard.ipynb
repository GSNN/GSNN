{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from GSNN import utils\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from GSNN.GSNNmodel import GSNN, GCN\n",
    "from GSNN.GSNNTrain import GSNNTrainer, GCNTrainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cora' # dataset = {'cora', 'citeseer', 'pubmed'}\n",
    "seed = 15 \n",
    "weight_decay = 5e-4\n",
    "lr = 1e-2\n",
    "hidden_dim = 16\n",
    "epochs = 200000\n",
    "earlystopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, labels = utils.load_data(dataset)\n",
    "_A_obs = adj\n",
    "# _X_obs = utils.preprocess_features(features)\n",
    "_X_obs = features\n",
    "_A_obs = _A_obs + _A_obs.T\n",
    "_A_obs[_A_obs > 1] = 1\n",
    "\n",
    "# _A_obs.setdiag(0)\n",
    "_A_obs = _A_obs.astype(\"float32\")\n",
    "_A_obs.eliminate_zeros()\n",
    "_X_obs = _X_obs.astype(\"float32\")\n",
    "\n",
    "_An = utils.preprocess_graph(_A_obs)\n",
    "split_train, split_val, split_test = np.where(train_mask)[0], np.where(val_mask)[0], np.where(test_mask)[0]\n",
    "split_unlabeled = np.union1d(split_val, split_test)\n",
    "_Z_obs = labels\n",
    "utils.set_seed(42, torch.cuda.is_available())\n",
    "adj = utils.sparse_mx_to_torch_sparse_tensor(_An).float()\n",
    "adj_cuda = adj.cuda()\n",
    "\n",
    "feature_cuda, label_cuda, idx_train_cuda, idx_val_cuda, idx_test_cuda = utils.convert_to_Tensor([_X_obs, _Z_obs, split_train, split_val, split_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An instantiation of GSNN-M model\n",
    "x_dim = feature_cuda.shape[1]\n",
    "y_dim = label_cuda.shape[1]\n",
    "h_dim, z_dim, r_dim = utils.get_h_dim(hidden_dim)\n",
    "\n",
    "gcn = GCN(x_dim, h_dim, y_dim, True)\n",
    "gsnn = GSNN(x_dim, y_dim, h_dim, r_dim, z_dim, gcn)\n",
    "\n",
    "optimizer = torch.optim.Adam(gsnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "gsnntrainer = GSNNTrainer(gsnn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "G:\\opensource\\GSNN\\GSNN\\GSNNTrain.py:102: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  kl_pq += (F.gumbel_softmax(y_encode[non_label].detach(), tau=1.0, hard=True) * (-F.log_softmax(y_pred_total[i][non_label]))).sum()/len(non_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train_loss: 13.860234260559082.\n",
      "--------------------------------------------------\n",
      "Epoch: 10, Train_loss: 6.2846198081970215.\n",
      "--------------------------------------------------\n",
      "Epoch: 20, Train_loss: 5.567917823791504.\n",
      "--------------------------------------------------\n",
      "Epoch: 30, Train_loss: 5.0991950035095215.\n",
      "--------------------------------------------------\n",
      "Epoch: 40, Train_loss: 4.623395919799805.\n",
      "--------------------------------------------------\n",
      "Epoch: 50, Train_loss: 4.309807300567627.\n",
      "--------------------------------------------------\n",
      "Epoch: 60, Train_loss: 3.899207830429077.\n",
      "--------------------------------------------------\n",
      "Epoch: 70, Train_loss: 3.56889009475708.\n",
      "--------------------------------------------------\n",
      "Epoch: 80, Train_loss: 3.4155068397521973.\n",
      "--------------------------------------------------\n",
      "Epoch: 90, Train_loss: 3.076070547103882.\n",
      "--------------------------------------------------\n",
      "Epoch: 100, Train_loss: 2.864795207977295.\n",
      "--------------------------------------------------\n",
      "Epoch: 110, Train_loss: 2.7166619300842285.\n",
      "--------------------------------------------------\n",
      "Epoch: 120, Train_loss: 2.5946571826934814.\n",
      "--------------------------------------------------\n",
      "Epoch: 130, Train_loss: 2.545213222503662.\n",
      "--------------------------------------------------\n",
      "Epoch: 140, Train_loss: 2.5265250205993652.\n",
      "--------------------------------------------------\n",
      "Epoch: 150, Train_loss: 2.4775397777557373.\n",
      "--------------------------------------------------\n",
      "Epoch: 160, Train_loss: 2.502068519592285.\n",
      "--------------------------------------------------\n",
      "Epoch: 170, Train_loss: 2.4202122688293457.\n",
      "--------------------------------------------------\n",
      "Epoch: 180, Train_loss: 2.38216233253479.\n",
      "--------------------------------------------------\n",
      "Epoch: 190, Train_loss: 2.3125998973846436.\n",
      "--------------------------------------------------\n",
      "Epoch: 200, Train_loss: 2.3297064304351807.\n",
      "--------------------------------------------------\n",
      "Epoch: 210, Train_loss: 2.262678861618042.\n",
      "--------------------------------------------------\n",
      "Epoch: 220, Train_loss: 2.355602979660034.\n",
      "--------------------------------------------------\n",
      "Epoch: 230, Train_loss: 2.1865971088409424.\n",
      "--------------------------------------------------\n",
      "Epoch: 240, Train_loss: 2.2472121715545654.\n",
      "--------------------------------------------------\n",
      "Epoch: 250, Train_loss: 2.08505916595459.\n",
      "--------------------------------------------------\n",
      "Epoch: 260, Train_loss: 2.1006035804748535.\n",
      "--------------------------------------------------\n",
      "Epoch: 270, Train_loss: 2.300417423248291.\n",
      "--------------------------------------------------\n",
      "Epoch: 280, Train_loss: 2.1279056072235107.\n",
      "--------------------------------------------------\n",
      "Epoch: 290, Train_loss: 2.127904176712036.\n",
      "--------------------------------------------------\n",
      "Epoch: 300, Train_loss: 2.0620298385620117.\n",
      "--------------------------------------------------\n",
      "Epoch: 310, Train_loss: 2.0826237201690674.\n",
      "--------------------------------------------------\n",
      "Epoch: 320, Train_loss: 2.07928204536438.\n",
      "--------------------------------------------------\n",
      "Epoch: 330, Train_loss: 2.0158157348632812.\n",
      "--------------------------------------------------\n",
      "Early stopping!\n",
      "Test_mean_acc: 0.839\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = gsnntrainer.train(adj_cuda, feature_cuda, label_cuda, idx_train_cuda, idx_val_cuda, idx_test_cuda, epochs, earlystopping=earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
