{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from GSNN import utils\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from GSNN.GSNNmodel import GSNN, GCN\n",
    "from GSNN.GSNNTrain import GSNNTrainer, GCNTrainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cora' # dataset = {'cora', 'citeseer', 'pubmed'}\n",
    "seed = 15 \n",
    "weight_decay = 5e-4\n",
    "lr = 1e-2\n",
    "hidden_dim = 16\n",
    "epochs = 200000\n",
    "earlystopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whb/anaconda3/envs/tf-gpu-cuda8/lib/python3.6/site-packages/scipy/sparse/lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/home/whb/anaconda3/envs/tf-gpu-cuda8/lib/python3.6/site-packages/scipy/sparse/lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    }
   ],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, labels = utils.load_data(dataset)\n",
    "_A_obs = adj\n",
    "# _X_obs = utils.preprocess_features(features)\n",
    "_X_obs = features\n",
    "_A_obs = _A_obs + _A_obs.T\n",
    "_A_obs[_A_obs > 1] = 1\n",
    "\n",
    "# _A_obs.setdiag(0)\n",
    "_A_obs = _A_obs.astype(\"float32\")\n",
    "_A_obs.eliminate_zeros()\n",
    "_X_obs = _X_obs.astype(\"float32\")\n",
    "\n",
    "_An = utils.preprocess_graph(_A_obs)\n",
    "split_train, split_val, split_test = np.where(train_mask)[0], np.where(val_mask)[0], np.where(test_mask)[0]\n",
    "split_unlabeled = np.union1d(split_val, split_test)\n",
    "_Z_obs = labels\n",
    "utils.set_seed(42, torch.cuda.is_available())\n",
    "adj = utils.sparse_mx_to_torch_sparse_tensor(_An).float()\n",
    "adj_cuda = adj.cuda()\n",
    "\n",
    "feature_cuda, label_cuda, idx_train_cuda, idx_val_cuda, idx_test_cuda = utils.convert_to_Tensor([_X_obs, _Z_obs, split_train, split_val, split_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An instantiation of GSNN-M model\n",
    "x_dim = feature_cuda.shape[1]\n",
    "y_dim = label_cuda.shape[1]\n",
    "h_dim, z_dim, r_dim = utils.get_h_dim(hidden_dim)\n",
    "\n",
    "gcn = GCN(x_dim, h_dim, y_dim, True)\n",
    "gsnn = GSNN(x_dim, y_dim, h_dim, r_dim, z_dim, gcn)\n",
    "\n",
    "optimizer = torch.optim.Adam(gsnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "gsnntrainer = GSNNTrainer(gsnn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whb/anaconda3/envs/tf-gpu-cuda8/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/whb/cx/GSNN-master/GSNN/GSNNTrain.py:102: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  kl_pq += (F.gumbel_softmax(y_encode[non_label].detach(), tau=1.0, hard=True) * (-F.log_softmax(y_pred_total[i][non_label]))).sum()/len(non_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train_loss: 13.860374450683594.\n",
      "--------------------------------------------------\n",
      "Epoch: 10, Train_loss: 6.296541213989258.\n",
      "--------------------------------------------------\n",
      "Epoch: 20, Train_loss: 5.569277763366699.\n",
      "--------------------------------------------------\n",
      "Epoch: 30, Train_loss: 5.124792098999023.\n",
      "--------------------------------------------------\n",
      "Epoch: 40, Train_loss: 4.937152862548828.\n",
      "--------------------------------------------------\n",
      "Epoch: 50, Train_loss: 4.464570999145508.\n",
      "--------------------------------------------------\n",
      "Epoch: 60, Train_loss: 3.9141578674316406.\n",
      "--------------------------------------------------\n",
      "Epoch: 70, Train_loss: 3.6885550022125244.\n",
      "--------------------------------------------------\n",
      "Epoch: 80, Train_loss: 3.288649559020996.\n",
      "--------------------------------------------------\n",
      "Epoch: 90, Train_loss: 3.1457865238189697.\n",
      "--------------------------------------------------\n",
      "Epoch: 100, Train_loss: 3.0050442218780518.\n",
      "--------------------------------------------------\n",
      "Epoch: 110, Train_loss: 2.8313748836517334.\n",
      "--------------------------------------------------\n",
      "Epoch: 120, Train_loss: 2.8240225315093994.\n",
      "--------------------------------------------------\n",
      "Epoch: 130, Train_loss: 2.690901279449463.\n",
      "--------------------------------------------------\n",
      "Epoch: 140, Train_loss: 2.488243579864502.\n",
      "--------------------------------------------------\n",
      "Epoch: 150, Train_loss: 2.4585165977478027.\n",
      "--------------------------------------------------\n",
      "Epoch: 160, Train_loss: 2.2947161197662354.\n",
      "--------------------------------------------------\n",
      "Epoch: 170, Train_loss: 2.3688714504241943.\n",
      "--------------------------------------------------\n",
      "Epoch: 180, Train_loss: 2.2029287815093994.\n",
      "--------------------------------------------------\n",
      "Epoch: 190, Train_loss: 2.2908222675323486.\n",
      "--------------------------------------------------\n",
      "Epoch: 200, Train_loss: 2.0976736545562744.\n",
      "--------------------------------------------------\n",
      "Epoch: 210, Train_loss: 2.1679935455322266.\n",
      "--------------------------------------------------\n",
      "Early stopping!\n",
      "Test_mean_acc: 0.843\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = gsnntrainer.train(adj_cuda, feature_cuda, label_cuda, idx_train_cuda, idx_val_cuda, idx_test_cuda, epochs, earlystopping=earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
